{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import modules as usual\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path of files\n",
    "path_positive_1 = '../eskin_data/yamamoto/throw/'\n",
    "path_negative_1 = '../eskin_data/yamamoto/others/'\n",
    "\n",
    "path_positive_2 = '../eskin_data/zennra/throw/'\n",
    "path_negative_2 = '../eskin_data/zennra/others/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the moment of throwing based on accel values\n",
    "def extract_action(df):\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    mom_action = int((np.argmax(abs(df.accelX))+ np.argmax(abs(df.accelY))+ np.argmax(abs(df.accelZ)))/3)\n",
    "    df = df.ix[mom_action-90:mom_action+90] \n",
    "    \n",
    "    df.index = df.time\n",
    "    df.drop([\"time\"], axis=1, inplace=True)\n",
    "    \n",
    "    return df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_positive_data(path):\n",
    "    path = os.path.join(path, '*.csv')\n",
    "    files = glob.glob(path)\n",
    "    \n",
    "    X_positives = []\n",
    "    \n",
    "    for file_path in files:\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        \n",
    "        df = extract_action(df)\n",
    "        \n",
    "        X_positives.append(df)\n",
    "        \n",
    "    X_positives = np.array(X_positives)\n",
    "    y_positives = np.ones(len(X_positives))\n",
    "        \n",
    "    return X_positives, y_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_negative_data(path, num_clip=100, random_state=71):\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    path = os.path.join(path, '*.csv')\n",
    "    files = glob.glob(path)\n",
    "    \n",
    "    X_negatives = []\n",
    "    \n",
    "    for file_path in files:\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        \n",
    "        for i in range(num_clip):\n",
    "            start = np.random.choice(range(len(df)-180))\n",
    "            \n",
    "            df_extracted = df.iloc[start:start+180].as_matrix()\n",
    "            X_negatives.append(df_extracted)\n",
    "        \n",
    "    X_negatives = np.array(X_negatives)\n",
    "    y_negatives = np.zeros(len(X_negatives))\n",
    "        \n",
    "    return X_negatives, y_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_matrix(X, size = (20, 20), flatten=False):\n",
    "    X_resized = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        X_ = X[i] /1.\n",
    "        X_ = cv2.resize(X_, size, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "        if flatten == True: # True for XGBoost etc., False for CNN (Convolutional Newral Networks) \n",
    "            X_ = X_.ravel()\n",
    "            \n",
    "        X_resized.append(X_)\n",
    "        \n",
    "    X_resized = np.array(X_resized)\n",
    "    \n",
    "    return X_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_baseline(X, y, num_augment=1, max_abs_tilt=0.1, max_abs_intercept=20, random_state=71):\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    \n",
    "    for j in range(num_augment): \n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            X_ = X[i].copy()\n",
    "            y_ = y[i].copy()\n",
    "           \n",
    "    \n",
    "            for col in range(X_.shape[1]-6):\n",
    "                tilt = np.random.uniform(-max_abs_tilt, max_abs_tilt)\n",
    "                intercept = np.random.uniform(-max_abs_intercept, max_abs_intercept)\n",
    "                \n",
    "                baseline = np.array(range(X_.shape[0])) * tilt + intercept\n",
    "                \n",
    "                X_[:,col] = X_[:,col] + baseline\n",
    "                \n",
    "            X_augmented.append(X_)\n",
    "            y_augmented.append(y_)\n",
    "                \n",
    "    X_augmented = np.array(X_augmented)\n",
    "    y_augmented = np.array(y_augmented)\n",
    "    \n",
    "    X = np.concatenate((X, X_augmented), axis=0)\n",
    "    y = np.concatenate((y, y_augmented), axis=0)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_positive_data(path, size = (20, 20), flatten=True, is_augment=True, num_augment=10, max_abs_tilt=5, max_abs_intercept=20, random_state=71):\n",
    "    X_positives, y_positives = load_positive_data(path)\n",
    "    \n",
    "    if is_augment == True:\n",
    "        X_positives, y_positives = add_baseline(X_positives, y_positives, num_augment=num_augment, max_abs_tilt=max_abs_tilt, max_abs_intercept=max_abs_intercept, random_state=random_state)\n",
    "        \n",
    "    X_positives = resize_matrix(X_positives, flatten=flatten)\n",
    "    \n",
    "    return X_positives, y_positives\n",
    "\n",
    "\n",
    "def prepare_negative_data(path, num_clip=500, size = (20, 20), flatten=True, is_augment=True, num_augment=10, max_abs_tilt=5, max_abs_intercept=20, random_state=71):\n",
    "    X_negatives, y_negatives = load_negative_data(path, num_clip=num_clip, random_state=random_state)\n",
    "    \n",
    "    if is_augment == True:\n",
    "        X_negatives, y_negatives = add_baseline(X_negatives, y_negatives, num_augment=num_augment, max_abs_tilt=max_abs_tilt, max_abs_intercept=max_abs_intercept, random_state=random_state)\n",
    "        \n",
    "    X_negatives = resize_matrix(X_negatives, flatten=flatten)\n",
    "    \n",
    "    return X_negatives, y_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 1人目（山本）のモーションデータをData Augmentationありで読み込む\n",
    "X_positives_1, y_positives_1 = prepare_positive_data(path_positive_1, is_augment=True, max_abs_tilt=5.0, num_augment=10)\n",
    "X_negatives_1, y_negatives_1 = prepare_negative_data(path_negative_1, is_augment=False)\n",
    "\n",
    "X_1_aug = np.concatenate((X_positives_1, X_negatives_1), axis=0)\n",
    "y_1_aug = np.concatenate((y_positives_1, y_negatives_1), axis=0)\n",
    "\n",
    "# 1人目（山本）のモーションデータをData Augmentationなしで読み込む\n",
    "X_positives_1, y_positives_1 = prepare_positive_data(path_positive_1, is_augment=False)\n",
    "X_negatives_1, y_negatives_1 = prepare_negative_data(path_negative_1, is_augment=False)\n",
    "\n",
    "X_1 = np.concatenate((X_positives_1, X_negatives_1), axis=0)\n",
    "y_1 = np.concatenate((y_positives_1, y_negatives_1), axis=0)\n",
    "\n",
    "\n",
    "# 2人目（武井氏）のモーションデータをData Augmentationありで読み込む\n",
    "X_positives_2, y_positives_2 = prepare_positive_data(path_positive_2, is_augment=True, max_abs_tilt=5.0, num_augment=10)\n",
    "X_negatives_2, y_negatives_2 = prepare_negative_data(path_negative_2, is_augment=False)\n",
    "\n",
    "X_2_aug = np.concatenate((X_positives_2, X_negatives_2), axis=0)\n",
    "y_2_aug = np.concatenate((y_positives_2, y_negatives_2), axis=0)\n",
    "\n",
    "# 2人目（武井氏）のモーションデータをData Augmentationなしで読み込む\n",
    "X_positives_2, y_positives_2 = prepare_positive_data(path_positive_2, is_augment=False)\n",
    "X_negatives_2, y_negatives_2 = prepare_negative_data(path_negative_2, is_augment=False)\n",
    "\n",
    "X_2 = np.concatenate((X_positives_2, X_negatives_2), axis=0)\n",
    "y_2 = np.concatenate((y_positives_2, y_negatives_2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((3100, 400), (3100,))\n",
      "((2100, 400), (2100,))\n",
      "((2001, 400), (2001,))\n",
      "((1091, 400), (1091,))\n"
     ]
    }
   ],
   "source": [
    "# それぞれのサイズを確認する\n",
    "print(X_1_aug.shape, y_1_aug.shape)\n",
    "print(X_1.shape, y_1.shape)\n",
    "\n",
    "print(X_2_aug.shape, y_2_aug.shape)\n",
    "print(X_2.shape, y_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Without Data Augmentation of train data, ROC-AUC: ', 0.98363736263736257)\n",
      "('With Data Augmentation of train data, ROC-AUC: ', 0.92542857142857149)\n"
     ]
    }
   ],
   "source": [
    "# 山本データで学習して、武井データに対して予測を行う。やや低下が見られたが依然として良好。\n",
    "# もう一方のfoldで大きなゲインが得られたことを考えるとトータルでは分類性能向上しているか。\n",
    "clf_xgb = XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7, \n",
    "                        gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3, \n",
    "                        min_child_weight=1, missing=None, n_estimators=100, nthread=-1, \n",
    "                        objective='binary:logistic', reg_alpha=0, reg_lambda=1, \n",
    "                        scale_pos_weight=1, seed=0, silent=True, subsample=0.7)\n",
    "\n",
    "clf_xgb.fit(X_1, y_1)\n",
    "probs = clf_xgb.predict_proba(X_2)[:,1]\n",
    "score = roc_auc_score(y_2, probs)\n",
    "print(\"Without Data Augmentation of train data, ROC-AUC: \", score)\n",
    "\n",
    "clf_xgb.fit(X_1_aug, y_1_aug)\n",
    "probs = clf_xgb.predict_proba(X_2)[:,1]\n",
    "score = roc_auc_score(y_2, probs)\n",
    "print(\"With Data Augmentation of train data, ROC-AUC: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Without Data Augmentation of train data, ROC-AUC: ', 0.83818499999999996)\n",
      "('With Data Augmentation of train data, ROC-AUC: ', 0.98306000000000004)\n"
     ]
    }
   ],
   "source": [
    "# 武井データで学習して、山本データに対して予測を行う。顕著な改善効果が認められた。\n",
    "clf_xgb = XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7, \n",
    "                        gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3, \n",
    "                        min_child_weight=1, missing=None, n_estimators=100, nthread=-1, \n",
    "                        objective='binary:logistic', reg_alpha=0, reg_lambda=1, \n",
    "                        scale_pos_weight=1, seed=0, silent=True, subsample=0.7)\n",
    "\n",
    "clf_xgb.fit(X_2, y_2)\n",
    "probs = clf_xgb.predict_proba(X_1)[:,1]\n",
    "score = roc_auc_score(y_1, probs)\n",
    "print(\"Without Data Augmentation of train data, ROC-AUC: \", score)\n",
    "\n",
    "clf_xgb.fit(X_2_aug, y_2_aug)\n",
    "probs = clf_xgb.predict_proba(X_1)[:,1]\n",
    "score = roc_auc_score(y_1, probs)\n",
    "print(\"With Data Augmentation of train data, ROC-AUC: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 何かLeakしている気がしなくもなく、嫌な予感がします。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
